set.seed(1)
library(mvtnorm)
library(mcmc)
library(invgamma)

# drifet function for Lorenz-63
drift_fun <- function(X, theta) {
    ans = c(theta[1] * (X[2] - X[1]), theta[2] * X[1] - X[2] - X[1] * X[3], X[1] * X[2] - theta[3] * X[3])
    return(t(t(ans)))
}

ludfun <- function(state) {
    # State is the vector storing the vectors of length 3*N + 12. The first 3*(N+1) terms are Xs. The next three terms are the parameters \sigma, \rho & 
    # \beta. The remaining 6 terms are the \Sigma matrix. Definition of Sigma below shows how the symmetric matrix is constructed.

    X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
    theta = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    


    # all the elements of theta should be positive
    if (min(theta) <= 0)
        return(-Inf)

    # Extracting observed data
    X_t = X_n[, seq(2, N + 1, N / K)]


    # pi is the log of likelihood
    # This doesn't need a loop
    #p1 = 0
    ##print(dim(Y))
    #for (k in 1:K) {
    #Y.t = t(t(Y[, k]))
    #X_t.t = t(t(X_t[, k]))
    #p1 = p1 + t(Y.t - X_t.t) %*% inv_R %*% (Y.t - X_t.t)
    #}
    #p1 = -0.5 * p1
    #p1 = p1 - 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o)

    #######################################################################
    p1 = (sum(dmvnorm(t(Y - X_t), sigma = R, log = TRUE))) + dmvnorm(t(X_n[, 1] - tau_o), sigma = lam_o, log = TRUE)
    #p1 = p1 - 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o))
    ######################################################################

    p2 = (alpha1 - 1) * log(theta[1]) - theta[1] / beta1 + (alpha2 - 1) * log(theta[2]) - theta[2] / beta2 + (alpha3 - 1) * log(theta[3]) - theta[3] / beta3


    f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, theta)
    del_X = t(diff(t(X_n)))
    beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
    p3 = -(a4 + N / 2) * sum(log(b4 + beta_tmp))

    return(p1 + p2 + p3)

}

linchpin <- function(n, init,sd) {
    X_avg = numeric(length = n.X)
    param_mat = matrix(, nrow = n, ncol = 6)
    scale = rep(0.001, n.X + n.theta)

    if (sd == 1) {
        scale[1:n.X] = 0.003
        scale[(n.X + 1):(n.X + n.theta)] = .45 #0.5
    }

    if (sd == 0.5) {
        scale[1:n.X] = 0.0017
        scale[(n.X + 1):(n.X + n.theta)] = .2
    }

    if (sd == 0.1) {
        scale[1:n.X] = 0.00065 # 0.0005
        scale[(n.X + 1):(n.X + n.theta)] = .05
    }

    if (sd == 0.05) {
        scale[1:n.X] = 0.0007 # 0.0004
        scale[(n.X + 1):(n.X + n.theta)] = .03
    }

    if (sd == 0.01) {
        scale[1:n.X] = 0.0006 # 0.0003
        scale[(n.X + 1):(n.X + n.theta)] = .02
    }
    
    accept.prob = 0

    for (i in 1:n) {

        if (i %% (n / 10) == 0) print(c(i, accept.prob / i))

        chain = metrop(ludfun, init, 1, scale = scale)
        state = chain$batch
        accept.prob = accept.prob + chain$accept
        X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
        theta = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta 
        X_avg = X_avg + state[1:n.X]
        param_mat[i, 1:3] = theta

        Sigma = numeric(length = 3)
        f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, theta)
        del_X = t(diff(t(X_n)))
        beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
        Sigma[1] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[1])
        Sigma[2] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[2])
        Sigma[3] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[3])

        param_mat[i, 4:6] = Sigma
        init = state
    }

    print(accept.prob / n)
    X_avg = X_avg / n
    final_output = list(param_mat, X_avg)
    return(final_output)
}


# Numerical method to sample from SDE
euler_maruyama <- function(X0, del_t, N, theta, Sigma) {
    X = matrix(, nrow = 3, ncol = N + 1)
    X[, 1] = X0
    for (i in 2:(N + 1))
        X[, i] = X[, i - 1] + t(drift_fun(X[, i - 1], theta)) * del_t + rmvnorm(1, sigma = del_t * Sigma)
    return(X)
}
# X = euler_maruyama(c(1,1,1), 0.1, 20, c(1,2,3), diag(2,3))


# hyper-parameters
to = 0 # initial time
tf = 20 # final time
Nobs = 10 # no of observations (Y) per time step
del_t = 0.01 # discrete approximation of dt
tau_o = matrix(c(0, 0, -25), nrow = 3, ncol = 1) # prior mean for X[0], i.e. initial state of Lorenz-63 oricess
lam_o = diag(10, 3) # prior covariance matrix of X[0]
inv.lam_o = solve(lam_o)
alpha1 = 20 # Prior for \sigma is Gamma (alpha1, beta1)
alpha2 = 56 # Prior for \rho is Gamma (alpha2, beta2)
alpha3 = 6 # Prior for \beta is Gamma (alpha3, beta3)
beta1 = 0.5
beta2 = 0.5
beta3 = 0.5
a4 = 2
b4 = .6
mu_truth = c(10, 28, 8 / 3)

K = (tf - to) * Nobs # no of real life observations, i.e. size of Y
N = (tf - to) / del_t # no of discretizations of the Lorenz-63, i.e. size of X
seq.Y = seq(2, N + 1, N / K)
N = tail(seq.Y, 1)
burn_in = 5000 / del_t
R = diag(.05, 3) # observational error
inv_R = solve(R)
n.X = 3 * (N + 1)
n.theta = 3
n.sigma = 3
n.param = n.X + n.theta + n.sigma
n = 1e5

#X_total = euler_maruyama(c(0,0,25), del_t, N + burn_in, mu_truth, diag(6, 3)) # generating sample from Lorenz-63
#X = X_total[, (burn_in):(N + burn_in)]

load('burninX6_by_10')
X = X[, 1:(N + 1)]
Y = X[, seq(2, N + 1, N / K)] + t(rmvnorm(K, mean = rep(0, 3), sigma = R)) # observations from Lorenz-63
init = numeric(n.X + n.theta)

# STARTING FROM TRUTH

init[(n.X + 1):(n.X + n.theta)] <- rmvnorm(1, c(10, 28, 8 / 3), sigma = diag(1/50   , 3)) # random initial values for MCMC

#X.interp = X #matrix(-50,nrow = 3, ncol = N + 1)
#y.index = 1
##X.interp[,1] = X[,1]
#for (i in seq(2, N + 1, N / K)) {
#if (i == 2) {
#X.interp[2] = Y[1]
#} else {
#X.interp[(i - N / K + 1):i] = seq(Y[y.index], Y[y.index + 1], (Y[y.index + 1] - Y[y.index]) * K / N)[-1]
#y.index = y.index + 1
#}

#}

#init[(1:n.X)] <- as.numeric(X.interp)

init[(1:n.X)] <- as.numeric(X) + rnorm(n.X, sd = 1) #runif(n.param, 0, 5)
ans = linchpin(n, init,1)
pm = ans[[1]]
colMeans(pm)

pdf(file = '1_jitter.pdf')
plot.ts(pm)
dev.off()

chain_info = capture.output(cat("no of samples from mc is ", n, " \n starting from truth ", "\n priors gamma", " time period ",
                                tf, " lam_0 is ", lam_o[1, 1], "nobs is ", Nobs, "sigma is ", 6, " R is ", R[1, 1]))

print(chain_info)
to_save = list(ans, chain_info,0.5)
save(to_save, file = "l63_jitter_1e5_sd_1")

init[(1:n.X)] <- as.numeric(X) + rnorm(n.X, sd = 0.5) #runif(n.param, 0, 5)
ans = linchpin(n, init,0.5)
pm = ans[[1]]
colMeans(pm)

pdf(file = '5_by_10_jitter.pdf')
plot.ts(pm)
dev.off()
to_save = list(ans, chain_info)
save(to_save, file = "l63_jitter_1e5_sd_5_by_10")

init[(1:n.X)] <- as.numeric(X) + rnorm(n.X, sd = .1) #runif(n.param, 0, 5)
ans = linchpin(n, init,0.1)
pm = ans[[1]]
colMeans(pm)

pdf(file = '1_by_10_jitter.pdf')
plot.ts(pm)
dev.off()
to_save = list(ans, chain_info)
save(to_save, file = "l63_jitter_1e5_sd_1_by_10")

init[(1:n.X)] <- as.numeric(X) + rnorm(n.X, sd = .05) #runif(n.param, 0, 5)
ans = linchpin(n, init,0.05)
pm = ans[[1]]
colMeans(pm)
pdf(file = '5_by_100_jitter.pdf')
plot.ts(pm)
dev.off()
to_save = list(ans, chain_info)
save(to_save, file = "l63_jitter_1e5_sd_5_by_100")

init[(1:n.X)] <- as.numeric(X) + rnorm(n.X, sd = .01) #runif(n.param, 0, 5)
ans = linchpin(n, init,0.01)
pm = ans[[1]]
colMeans(pm)
pdf(file = '1_y_100_jitter.pdf')
plot.ts(pm)
dev.off()
to_save = list(ans, chain_info)
save(to_save, file = "l63_jitter_1e5_sd_1_by_100")

#init[(1:n.X)] <- as.numeric(X) + rnorm(n.X, sd = 0.005) #runif(n.param, 0, 5)
#ans = linchpin(n, init)
#pm = ans[[1]]
#colMeans(pm)
#to_save = list(ans, chain_info)
#save(to_save, file = "l63_jitter_1e5_sd_5_by_1000")
