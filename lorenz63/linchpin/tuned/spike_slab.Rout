
R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> set.seed(1)
> library(mvtnorm)
> library(mcmc)
> library(invgamma)
> 
> make_tilde <- function(X, t) {
+     X_vec = c(X[1], X[2], X[3], X[1] ^ 2, X[2] ^ 2, X[3] ^ 2, X[1] * X[2], X[2] * X[3], X[3] * X[1], t, t ^ 2)
+     return(X_vec)
+ }
> # drifet function for Lorenz-63
> drift_fun <- function(X, t, B) {
+     #print(make_tilde(X,t))
+     tildeX = matrix(make_tilde(X, t), nrow = 11, ncol = 1)
+     B_mat = matrix(B, nrow = 3)
+     #print(B)
+     #print(dim(tildeX))
+     ans = B_mat %*% tildeX
+     return(ans)
+ }
> 
> drift_fun_true <- function(X, theta) {
+     ans = c(theta[1] * (X[2] - X[1]), theta[2] * X[1] - X[2] - X[1] * X[3], X[1] * X[2] - theta[3] * X[3])
+     return(t(t(ans)))
+ }
> 
> ludfun <- function(state, gamma) {
+     # State is the vector storing the vectors of length 3*N + 12. The first 3*(N+1) terms are Xs. The next three terms are the parameters \sigma, \rho & 
+     # \beta. The remaining 6 terms are the \Sigma matrix. Definition of Sigma below shows how the symmetric matrix is constructed.
+     #if (index == 0) {
+         ##print('0')
+         #all[1:n.X] = state
+     #} else {
+         ##print(index)
+         #all[n.X+index] = state
+     #}
+ 
+     #X_n = matrix(all[1:n.X], nrow = 3, ncol = N + 1)
+     #B_vec = all[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     #B_mat = matrix(B_vec, nrow = 3)
+ 
+     X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
+     B_vec = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     B_mat = matrix(B_vec, nrow = 3)
+ 
+     # all the elements of theta should be positive
+     #if (min(theta) <= 0)
+     #return(-Inf)
+ 
+     # Extracting observed data
+     X_t = X_n[, seq(2, N + 1, N / K)]
+ 
+ 
+     # pi is the log of likelihood
+     # This doesn't need a loop
+     p1 = 0
+     #print(dim(Y))
+     for (k in 1:K) {
+         Y.t = t(t(Y[, k]))
+         X_t.t = t(t(X_t[, k]))
+         p1 = p1 + t(Y.t - X_t.t) %*% inv_R %*% (Y.t - X_t.t)
+     }
+     p1 = -0.5 * p1
+     p1 = p1 - 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o)
+ 
+     #######################################################################
+     #p1 = (sum(dmvnorm(t(Y - X_t), sigma = R, log = TRUE))
+     #- 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o))
+     ######################################################################
+     B_cov_gamma = gamma * (tau1 ^ 2) + (1 - gamma) * (tau0 ^ 2)
+     p2 = dmvnorm(B_vec, sigma = diag(B_cov_gamma), log = TRUE)
+     #p2 = (-1 / 2) * sum((B_vec - mu) ^ 2) / sigma2
+ 
+     f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(B_vec))
+     #f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, B_vec, list(1,2))
+     del_X = t(diff(t(X_n)))
+     beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+     p3 = - (a4 + N / 2) * sum(log(b4 + beta_tmp))
+ 
+     return(p1 + p2 + p3)
+ 
+ }
> 
> sample_gamma <- function(B_vec) {
+     gamma = numeric(length = n.theta)
+     for (i in 1:n.theta) {
+         prob = q[i] * dnorm(B_vec[i], sd = tau1) / (q[i] * dnorm(B_vec[i], sd = tau1) + (1 - q[i]) * dnorm(B_vec[i], sd = tau0))
+         gamma[i] = rbinom(1,1,prob)
+     }
+     return(gamma)
+ }
> 
> MH.X <- function(init, n, scale, gamma, B_vec) {
+     chain = matrix(, nrow = n, ncol = n.X)
+     accept.prob = 0
+     for (i in 1:n) {
+         prop = sapply(init, function(t) rnorm(1, t, scale))
+         prop_ludf = c(prop, B_vec)
+         init_ludf = c(init, B_vec)
+         if ( log(runif(1)) < (ludfun(prop_ludf, gamma) - ludfun(init_ludf, gamma)) ) {
+             init = prop
+             accept.prob = accept.prob+1
+         }
+         chain[i,] = init
+     }
+     ans = list(chain, accept.prob / n)
+     return(ans)
+ }
> 
> MH.B <- function(index, init, n, scale, gamma, state) {
+     chain = numeric(length = n)
+     accept.prob = 0
+     prop_ludf = state
+     init_ludf = state
+     for (i in 1:n) {
+         prop = rnorm(1, init, scale)
+         prop_ludf[n.X + index] = prop
+         init_ludf[n.X + index] = init
+         if ( log(runif(1)) < (ludfun(prop_ludf, gamma) - ludfun(init_ludf, gamma)) ) {
+             init = prop
+             accept.prob = accept.prob + 1
+         }
+         chain[i] = init
+     }
+     ans = list(chain, accept.prob / n)
+     return(ans)
+ }
> 
> linchpin <- function(n, init, scale_vec) {
+     X_avg = numeric(length = n.X)
+     param_mat = matrix(, nrow = n, ncol = 2*n.theta + n.sigma)
+     scale = rep(0.0001 * 1, n.X + n.theta)
+     scale[(n.X + 1):(n.X + n.theta)] = 0.001
+     scale[n.X + non_zero] = .4 * scale_vec[non_zero]
+     scale[n.X + param_i] = 1 * scale_vec[param_i]
+     scale[n.X + non_zero[c(5)]] = 1.4 * scale_vec[non_zero[c(5)]]
+     scale[n.X + non_zero[c(4)]] = 1.5 * scale_vec[non_zero[c(4)]]
+     scale[n.X + param_i[c(2)]] = 2 * scale_vec[param_i[c(2)]]
+     #scale[n.X + c(3, 6)] = 0.001 * 5
+     #scale[n.X + c(1,3,4,6,7,8,10,11,12,13,14,] = 10 * scale[n.X + 1]
+     scale[(n.X + 1):(n.X + n.theta)] = scale_vec
+     scale[n.X + c(6, 25)] = 0.8 * scale[n.X + c(6, 25)]
+     scale[n.X + c(7, 8, 13, 14, 15, 17, 22, 23, 24, 28, 29, 30, 31, 32, 33)] = 0.5 * scale[n.X + c(7, 8, 13, 14, 15, 17, 22, 23, 24, 28, 29, 30, 31, 32, 33)]
+     scale[n.X + c(9, 10, 11, 12, 16, 18, 19, 20, 21)] = 0.2 * scale[n.X + c(9, 10, 11, 12, 16, 18, 19, 20, 21)]
+     scale[n.X + c(3, 4, 8,10, 11, 12, 16, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33)] = 1.5 * scale[n.X + c(3, 4, 8, 10, 11, 12, 16, 19, 20, 21, 22, 23, 24, 28, 30, 31, 32, 33)]
+     scale[n.X + c(17, 20, 21, 24)] = 0.8 * scale[n.X + c(17,20,21, 24)]
+     scale[n.X + c(3, 9, 16, 33)] = 1.3 * scale[n.X + c(3, 9, 16, 33)]
+ 
+     scale.X = 0.0001
+     scale.B = scale[(n.X + 1):(n.X + n.theta)]
+     
+     accept.prob = numeric(1 + n.theta)
+     state = init
+ 
+     for (i in 1:n) {
+         gamma = sample_gamma(init[(n.X + 1):(n.X + n.theta)])
+         param_mat[i, (n.theta + n.sigma + 1):(2 * n.theta + n.sigma)] = gamma
+ 
+         if (i %% (n / 5) == 0) {
+             print(i)
+             print(matrix(accept.prob[2:(n.theta+1)]/i, nrow = 3))
+             #print(c(i, accept.prob / i))
+         }
+ 
+         #all = init
+         #chain = metrop(ludfun, initial = init[1:n.X], nbatch = 1, scale = scale.X, gamma = gamma, all = all, index = 0)
+         #accept.prob[1] = accept.prob[1] + chain$accept
+         #init[1:n.X] = chain$batch
+ 
+         ans = MH.X(init[1:n.X], 1, scale.X, gamma, init[(n.X + 1):(n.X + n.theta)])
+         accept.prob[1] = accept.prob[1] + ans[[2]]
+         init[1:n.X] = ans[[1]]
+ 
+         for (j in 1:n.theta) {
+             #all = init
+             #chain = metrop(ludfun, initial = init[n.X + j], nbatch = 1, scale = scale.B[j], gamma = gamma, all = all, index = j)
+             #accept.prob[j + 1] = accept.prob[j + 1] + chain$accept
+             #init[n.X + j] = chain$batch
+ 
+             ans = MH.B(j, init[n.X + j], 1, scale.B[j], gamma, state)
+             accept.prob[j + 1] = accept.prob[j + 1] + ans[[2]]
+             init[n.X+j] = ans[[1]]
+         }
+         state = init
+         #chain = metrop(ludfun, init, 1, scale = scale, gamma = gamma)
+         #state = chain$batch
+         #accept.prob = accept.prob + chain$accept
+         
+         X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
+         theta = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta 
+         X_avg = X_avg + state[1:n.X]
+         param_mat[i, 1:n.theta] = theta
+ 
+         Sigma = numeric(length = 3)
+         f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(theta))
+         del_X = t(diff(t(X_n)))
+         beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+         Sigma[1] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[1])
+         Sigma[2] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[2])
+         Sigma[3] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[3])
+ 
+         param_mat[i, (n.theta + 1):(n.theta + n.sigma)] = Sigma
+         init = state
+     }
+     print(accept.prob / n)
+     X_avg = X_avg / n
+     final_output = list(param_mat, X_avg)
+     return(final_output)
+ }
> 
> 
> # Numerical method to sample from SDE
> euler_maruyama <- function(X0, del_t, N, theta, Sigma) {
+     X = matrix(, nrow = 3, ncol = N + 1)
+     X[, 1] = X0
+     for (i in 2:(N + 1))
+         X[, i] = X[, i - 1] + t(drift_fun_true(X[, i - 1], theta)) * del_t + rmvnorm(1, sigma = del_t * Sigma)
+     return(X)
+ }
> # X = euler_maruyama(c(1,1,1), 0.1, 20, c(1,2,3), diag(2,3))
> 
> 
> # hyper-parameters
> to = 0 # initial time
> tf = 20 # final time
> Nobs = 10 # no of observations (Y) per time step
> del_t = 0.01 # discrete approximation of dt
> tau_o = matrix(rep(0, 3), nrow = 3, ncol = 1) # prior mean for X[0], i.e. initial state of Lorenz-63 oricess
> lam_o = diag(10, 3) # prior covariance matrix of X[0]
> inv.lam_o = solve(lam_o)
> alpha1 = 20 # Prior for \sigma is Gamma (alpha1, beta1)
> alpha2 = 56 # Prior for \rho is Gamma (alpha2, beta2)
> alpha3 = 6 # Prior for \beta is Gamma (alpha3, beta3)
> beta1 = 0.5
> beta2 = 0.5
> beta3 = 0.5
> a4 = 2
> b4 = 6
> tau1 = 10
> tau0 = 0.5
> 
> K = (tf - to) * Nobs # no of real life observations, i.e. size of Y
> N = (tf - to) / del_t # no of discretizations of the Lorenz-63, i.e. size of X
> burn_in = 5000 / del_t
> R = diag(1/2, 3) # observational error
> inv_R = solve(R)
> mu = 0
> sigma2 = 10
> mu_truth = c(-10, 28, 0, 10, -1, rep(0, 3), -8 / 3, rep(0, 11), 1, rep(0, 4), -1, rep(0, 7))
> n.X = 3 * (N + 1)
> n.theta = 33
> n.sigma = 3
> n.param = n.X + n.theta + n.sigma
> q = rep(0.5,n.theta) #runif(n.theta)
> n <- 1e4
> 
> #X_total = euler_maruyama(c(0,0,25), del_t, N + burn_in, c(10, 28, 8 / 3), diag(6, 3)) # generating sample from Lorenz-63
> #X = X_total[, (burn_in):(N + burn_in)]
> load('../../burninX')
> Y = X[, seq(2, N + 1, N / K)] + t(rmvnorm(K, mean = rep(0, 3), sigma = R)) # observations from Lorenz-63
> init = numeric(n.X + n.theta)
> init[(1:n.X)] <- as.numeric(X) #runif(n.param, 0, 5)
> 
> init[(n.X + 1):(n.X + n.theta)] <- rmvnorm(1, mu_truth, sigma = diag(1 / 50, n.theta))
> non_zero = c(4, 5, 7, 8, 12, 24, 29) - 3
> param_i = c(1, 2, 4, 9)
> load("../../l63_linch_reg_bsv_0001_T_20_pv_10_init")
> init[(n.X + 1):(n.X + n.theta)] <- head(tail(ans[[1]], 1)[1, - c(1, 2, 3)], -3)
> init[n.X+5] = -0.8
> 
> sigma_Y = mean(diag(var(t(Y))))
> tau0 = sqrt(sigma_Y / (10 * K))
> tau1 = sqrt(sigma_Y * max((n.theta^2.1)/(100*K), log(K)))
> 
> load('../l63_linch_T_20_5e5_1')
> var1 = cov(to_save[[1]][[1]][, 1:33])
> scale_vec = 3 * sqrt(diag(var1))
> ans = linchpin(n, init, scale_vec)
[1] 2000
       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
[1,] 0.2690 0.2755 0.2685 0.3160 0.2460 0.2755 0.2530 0.2665 0.2670 0.2715
[2,] 0.2695 0.2755 0.2310 0.2580 0.2530 0.2475 0.2795 0.2220 0.2440 0.3190
[3,] 0.2430 0.2235 0.2350 0.2205 0.2405 0.2540 0.2465 0.2455 0.2275 0.2220
      [,11]
[1,] 0.2785
[2,] 0.2870
[3,] 0.2490
[1] 4000
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 0.26825 0.27225 0.27600 0.30750 0.25575 0.26850 0.25450 0.26000 0.26600
[2,] 0.26025 0.26250 0.22825 0.25350 0.24875 0.23950 0.27125 0.21825 0.22675
[3,] 0.23625 0.22100 0.24700 0.21775 0.22725 0.24775 0.24375 0.24075 0.23350
       [,10]   [,11]
[1,] 0.26675 0.28000
[2,] 0.31250 0.26775
[3,] 0.22800 0.23625
[1] 6000
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2555000 0.2750000 0.2770000 0.2996667 0.2581667 0.2643333 0.2541667
[2,] 0.2601667 0.2648333 0.2261667 0.2555000 0.2476667 0.2360000 0.2646667
[3,] 0.2348333 0.2236667 0.2470000 0.2173333 0.2246667 0.2470000 0.2410000
          [,8]      [,9]     [,10]     [,11]
[1,] 0.2555000 0.2670000 0.2671667 0.2770000
[2,] 0.2193333 0.2206667 0.3013333 0.2616667
[3,] 0.2403333 0.2318333 0.2355000 0.2348333
[1] 8000
         [,1]     [,2]     [,3]     [,4]    [,5]     [,6]     [,7]     [,8]
[1,] 0.255500 0.270250 0.274625 0.295625 0.26125 0.262750 0.252625 0.252500
[2,] 0.261250 0.269500 0.232250 0.260500 0.25075 0.244375 0.267625 0.227000
[3,] 0.231375 0.226125 0.244750 0.217250 0.22300 0.249875 0.238375 0.239625
         [,9]    [,10]    [,11]
[1,] 0.268125 0.264375 0.275500
[2,] 0.227625 0.303500 0.267375
[3,] 0.234875 0.234875 0.237375
[1] 10000
       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
[1,] 0.2600 0.2722 0.2761 0.2973 0.2611 0.2607 0.2518 0.2571 0.2662 0.2632
[2,] 0.2602 0.2708 0.2332 0.2561 0.2537 0.2417 0.2627 0.2241 0.2264 0.3020
[3,] 0.2306 0.2223 0.2428 0.2161 0.2228 0.2502 0.2391 0.2379 0.2345 0.2360
      [,11]
[1,] 0.2768
[2,] 0.2646
[3,] 0.2377
 [1] 0.9831 0.2600 0.2602 0.2306 0.2722 0.2708 0.2223 0.2761 0.2332 0.2428
[11] 0.2973 0.2561 0.2161 0.2611 0.2537 0.2228 0.2607 0.2418 0.2502 0.2519
[21] 0.2628 0.2392 0.2571 0.2241 0.2380 0.2662 0.2264 0.2345 0.2633 0.3020
[31] 0.2360 0.2769 0.2646 0.2377
> #plot.ts(ans[[1]][, param_i])
> #plot.ts(ans[[1]][, non_zero])
> chain_info = capture.output(cat("no of samples from MC is ", n, " \n starting from init ", "\n priors spike slab ", " time period ",
+                             tf, " lam_0 is 10"))
> 
> print(chain_info)
[1] "no of samples from MC is  10000  "                
[2] " starting from init  "                            
[3] " priors spike slab   time period  20  lam_0 is 10"
> to_save = list(ans, chain_info)
> save(to_save, file = "l63_linch_T_20_cwise_1_spikes")
> pm = ans[[1]][,1:(n.sigma+n.theta)]
> 
> print(matrix(colMeans(pm), nrow = 3))
            [,1]         [,2]        [,3]       [,4]         [,5]         [,6]
[1,] -8.14807189  8.801786960 -0.06997267 0.01809490  0.022515640  0.002491547
[2,] 27.47050965 -0.128899937  0.19148102 0.03830501 -0.011091412 -0.009195763
[3,] -0.07372769 -0.006801461 -2.19976220 0.13897208  0.002702841 -0.018806365
            [,7]         [,8]        [,9]      [,10]         [,11]    [,12]
[1,] -0.05390383  0.035029643 -0.05297119 -0.0396860  0.0001896194 6.582977
[2,] -0.01173459 -0.031922502 -0.97974160  0.2398587 -0.0134870160 6.031795
[3,]  0.89158916  0.004404334  0.00301056 -0.2091136  0.0128568596 6.062091
> 
> pm2 = ans[[1]][, (n.sigma + n.theta + 1):(n.sigma + 2*n.theta)]
> print(matrix(colMeans(pm2), nrow = 3))
       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
[1,] 1.0000 1.0000 0.0622 0.0106 0.0102 0.0086 0.0093 0.0102 0.0095 0.1476
[2,] 1.0000 0.2925 0.1857 0.0128 0.0098 0.0088 0.0138 0.0081 0.9996 0.2237
[3,] 0.0861 0.0415 1.0000 0.0133 0.0099 0.0086 0.9887 0.0107 0.0106 0.2586
      [,11]
[1,] 0.0093
[2,] 0.0106
[3,] 0.0104
> 
> proc.time()
    user   system  elapsed 
16676.16    93.64 17044.64 
