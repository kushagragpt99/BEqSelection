
R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> set.seed(1)
> library(mvtnorm)
> library(mcmc)
> library(invgamma)
> 
> make_tilde <- function(X, t) {
+     X_vec = c(X[1], X[2], X[3], X[1] ^ 2, X[2] ^ 2, X[3] ^ 2, X[1] * X[2], X[2] * X[3], X[3] * X[1], t, t ^ 2)
+     return(X_vec)
+ }
> # drifet function for Lorenz-63
> drift_fun <- function(X, t, B) {
+     #print(make_tilde(X,t))
+     tildeX = matrix(make_tilde(X, t), nrow = 11, ncol = 1)
+     B_mat = matrix(B, nrow = 3)
+     #print(B)
+     #print(dim(tildeX))
+     ans = B_mat %*% tildeX
+     return(ans)
+ }
> 
> drift_fun_true <- function(X, theta) {
+     ans = c(theta[1] * (X[2] - X[1]), theta[2] * X[1] - X[2] - X[1] * X[3], X[1] * X[2] - theta[3] * X[3])
+     return(t(t(ans)))
+ }
> 
> ludfun <- function(state, gamma) {
+     # State is the vector storing the vectors of length 3*N + 12. The first 3*(N+1) terms are Xs. The next three terms are the parameters \sigma, \rho & 
+     # \beta. The remaining 6 terms are the \Sigma matrix. Definition of Sigma below shows how the symmetric matrix is constructed.
+     #if (index == 0) {
+     ##print('0')
+     #all[1:n.X] = state
+     #} else {
+     ##print(index)
+     #all[n.X+index] = state
+     #}
+ 
+     #X_n = matrix(all[1:n.X], nrow = 3, ncol = N + 1)
+     #B_vec = all[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     #B_mat = matrix(B_vec, nrow = 3)
+ 
+     X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
+     B_vec = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     B_mat = matrix(B_vec, nrow = 3)
+ 
+     # all the elements of theta should be positive
+     #if (min(theta) <= 0)
+     #return(-Inf)
+ 
+     # Extracting observed data
+     X_t = X_n[, seq(2, N + 1, N / K)]
+ 
+ 
+     #######################################################################
+     p1 = (sum(dmvnorm(t(Y - X_t), sigma = R, log = TRUE))) + dmvnorm(t(X_n[, 1] - tau_o), sigma = lam_o, log = TRUE)
+     #- 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o))
+     ######################################################################
+     B_cov_gamma = gamma * (tau1 ^ 2) + (1 - gamma) * (tau0 ^ 2)
+     p2 = dmvnorm(B_vec, sigma = diag(B_cov_gamma), log = TRUE)
+     #p2 = (-1 / 2) * sum((B_vec - mu) ^ 2) / sigma2
+ 
+     f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(B_vec))
+     #f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, B_vec, list(1,2))
+     del_X = t(diff(t(X_n)))
+     beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+     p3 = -(a4 + N / 2) * sum(log(b4 + beta_tmp))
+ 
+     return(p1 + p2 + p3)
+ 
+ }
> 
> ludfun.X <- function(state, gamma, all) {
+     # State is the vector storing the vectors of length 3*N + 12. The first 3*(N+1) terms are Xs. The next three terms are the parameters \sigma, \rho & 
+     # \beta. The remaining 6 terms are the \Sigma matrix. Definition of Sigma below shows how the symmetric matrix is constructed.
+     #if (index == 0) {
+     ##print('0')
+     #all[1:n.X] = state
+     #} else {
+     ##print(index)
+     #all[n.X+index] = state
+     #}
+     all[1:n.X] = state
+     X_n = matrix(all[1:n.X], nrow = 3, ncol = N + 1)
+     B_vec = all[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     B_mat = matrix(B_vec, nrow = 3)
+ 
+     #X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
+     #B_vec = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     #B_mat = matrix(B_vec, nrow = 3)
+ 
+     # all the elements of theta should be positive
+     #if (min(theta) <= 0)
+     #return(-Inf)
+ 
+     # Extracting observed data
+     X_t = X_n[, seq(2, N + 1, N / K)]
+ 
+     #######################################################################
+     p1 = (sum(dmvnorm(t(Y - X_t), sigma = R, log = TRUE))) + dmvnorm(t(X_n[, 1] - tau_o), sigma = lam_o, log = TRUE)
+     ######################################################################
+     B_cov_gamma = gamma * (tau1 ^ 2) + (1 - gamma) * (tau0 ^ 2)
+     p2 = dmvnorm(B_vec, sigma = diag(B_cov_gamma), log = TRUE)
+     #p2 = (-1 / 2) * sum((B_vec - mu) ^ 2) / sigma2
+ 
+     f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(B_vec))
+     #f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, B_vec, list(1,2))
+     del_X = t(diff(t(X_n)))
+     beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+     p3 = -(a4 + N / 2) * sum(log(b4 + beta_tmp))
+ 
+     return(p1 + p2 + p3)
+ 
+ }
> 
> sample_gamma <- function(B_vec) {
+     gamma = numeric(length = n.theta)
+     for (i in 1:n.theta) {
+         prob = q[i] * dnorm(B_vec[i], sd = tau1) / (q[i] * dnorm(B_vec[i], sd = tau1) + (1 - q[i]) * dnorm(B_vec[i], sd = tau0))
+         gamma[i] = rbinom(1, 1, prob)
+     }
+     return(gamma)
+ }
> 
> MH.X <- function(init, n, scale, gamma, B_vec) {
+     chain = matrix(, nrow = n, ncol = n.X)
+     accept.prob = 0
+     for (i in 1:n) {
+         prop = sapply(init, function(t) rnorm(1, t, scale))
+         prop_ludf = c(prop, B_vec)
+         init_ludf = c(init, B_vec)
+         if (log(runif(1)) < (ludfun(prop_ludf, gamma) - ludfun(init_ludf, gamma))) {
+             init = prop
+             accept.prob = accept.prob + 1
+         }
+         chain[i,] = init
+     }
+     ans = list(chain, accept.prob / n)
+     return(ans)
+ }
> 
> MH.B <- function(index, init, n, scale, gamma, state) {
+     chain = numeric(length = n)
+     accept.prob = 0
+     prop_ludf = state
+     init_ludf = state
+     for (i in 1:n) {
+         prop = rnorm(1, init, scale)
+         prop_ludf[n.X + index] = prop
+         init_ludf[n.X + index] = init
+         if (log(runif(1)) < (ludfun(prop_ludf, gamma) - ludfun(init_ludf, gamma))) {
+             init = prop
+             accept.prob = accept.prob + 1
+         }
+         chain[i] = init
+     }
+     ans = list(chain, accept.prob / n)
+     return(ans)
+ }
> 
> linchpin <- function(n, init, scale_vec) {
+     X_avg = numeric(length = n.X)
+     param_mat = matrix(, nrow = n, ncol = 2 * n.theta + n.sigma)
+     scale = rep(0.0001 * 1, n.X + n.theta)
+     scale[(n.X + 1):(n.X + n.theta)] = 0.6*scale_vec
+     scale[n.X + non_zero[c(1,7)]] = 0.3 * scale_vec[non_zero[c(1,7)]]
+     scale[n.X + non_zero[c(3)]] = 0.7 * scale_vec[non_zero[c(3)]]
+     scale[n.X + non_zero[c(2,4)]] = 0.4 * scale_vec[non_zero[c(2,4)]]
+     scale[n.X + non_zero[c(5)]] = 0.08 * scale_vec[non_zero[c(5)]]
+     scale[n.X + non_zero[c(6)]] = 0.07 * scale_vec[non_zero[c(6)]]
+     scale[n.X + c(3)] = 0.4 * scale_vec[c(3)]
+     scale[n.X + c(5)] = 0.7 * scale_vec[c(5)]
+     scale[n.X + c(10)] = 0.1 * scale_vec[c(10)]
+     scale[n.X + c(27, 33)] = 0.3 * scale_vec[c(27,23)]
+     scale[n.X + c(11,15, 16,17,19)] = 0.11 * scale_vec[c(11,15,16,17,19)]
+     scale[n.X + c(6,7,8,13,14,24)] = 0.18 * scale_vec[c(6,7,8,13,14,24)]
+     scale[n.X + c(12)] = 0.07 * scale_vec[c(12)]
+     scale[n.X + c(31,32)] = 0.2 * scale_vec[c(31,32)]
+     scale[n.X + c(22,23,25,26)] = 0.3 * scale_vec[c(22,23,25,26)]
+     scale[n.X + c(18)] = 0.05 * scale_vec[c(18)]
+     scale[n.X + c(28, 29)] = 0.18 * scale_vec[c(28, 29)]
+     scale[n.X + c(20)] = 0.12 * scale_vec[c(20)]
+     #scale[n.X + non_zero] = .4 * scale_vec[non_zero]
+     #scale[n.X + param_i] = 1 * scale_vec[param_i]
+     #scale[n.X + non_zero[c(5)]] = 1.4 * scale_vec[non_zero[c(5)]]
+     #scale[n.X + non_zero[c(4)]] = 1.5 * scale_vec[non_zero[c(4)]]
+     #scale[n.X + param_i[c(2)]] = 2 * scale_vec[param_i[c(2)]]
+     #scale[n.X + c(3, 6)] = 0.001 * 5
+     #scale[n.X + c(1,3,4,6,7,8,10,11,12,13,14,] = 10 * scale[n.X + 1]
+     #scale[(n.X + 1):(n.X + n.theta)] = scale_vec
+     #scale[n.X + c(6, 25)] = 0.8 * scale[n.X + c(6, 25)]
+     #scale[n.X + c(7, 8, 13, 14, 15, 17, 22, 23, 24, 28, 29, 30, 31, 32, 33)] = 0.5 * scale[n.X + c(7, 8, 13, 14, 15, 17, 22, 23, 24, 28, 29, 30, 31, 32, 33)]
+     #scale[n.X + c(9, 10, 11, 12, 16, 18, 19, 20, 21)] = 0.2 * scale[n.X + c(9, 10, 11, 12, 16, 18, 19, 20, 21)]
+     #scale[n.X + c(3, 4, 8, 10, 11, 12, 16, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33)] = 1.5 * scale[n.X + c(3, 4, 8, 10, 11, 12, 16, 19, 20, 21, 22, 23, 24, 30, 31, 32, 33)]
+     #scale[n.X + c(17, 20, 21, 24)] = 0.8 * scale[n.X + c(17, 20, 21, 24)]
+     #scale[n.X + c(9, 16, 33)] = 1.3 * scale[n.X + c(9, 16, 33)]
+     #scale[n.X + c(3, 8, 28)] = 0.6 * scale[n.X + c(3, 8, 28)]
+     #scale[n.X + c(7,29)] = 0.5*scale[n.X+c(7,29)]
+ 
+     scale.X = 0.0001
+     scale.B = scale[(n.X + 1):(n.X + n.theta)]
+ 
+     accept.prob = numeric(1 + n.theta)
+     state = init
+ 
+     for (i in 1:n) {
+         gamma = sample_gamma(init[(n.X + 1):(n.X + n.theta)])
+         param_mat[i, (n.theta + n.sigma + 1):(2 * n.theta + n.sigma)] = gamma
+ 
+         if (i %% (n / 10) == 0) {
+             print(i)
+             print(matrix(accept.prob[2:(n.theta + 1)] / i, nrow = 3))
+             #print(c(i, accept.prob / i))
+         }
+ 
+         all = init
+         chain = metrop(ludfun.X, initial = init[1:n.X], nbatch = 1, scale = scale.X, gamma = gamma, all = all)
+         accept.prob[1] = accept.prob[1] + chain$accept
+         state[1:n.X] = chain$batch
+ 
+         #ans = MH.X(init[1:n.X], 1, scale.X, gamma, init[(n.X + 1):(n.X + n.theta)])
+         #accept.prob[1] = accept.prob[1] + ans[[2]]
+         #init[1:n.X] = ans[[1]]
+ 
+         for (j in 1:n.theta) {
+             ####### are you considering updated values of B for next steps??????
+             #all = init
+             #chain = metrop(ludfun, initial = init[n.X + j], nbatch = 1, scale = scale.B[j], gamma = gamma, all = all, index = j)
+             #accept.prob[j + 1] = accept.prob[j + 1] + chain$accept
+             #init[n.X + j] = chain$batch
+ 
+             ans = MH.B(j, init[n.X + j], 1, scale.B[j], gamma, state)
+             accept.prob[j + 1] = accept.prob[j + 1] + ans[[2]]
+             state[n.X + j] = ans[[1]]
+         }
+ 
+         #chain = metrop(ludfun, init, 1, scale = scale, gamma = gamma)
+         #state = chain$batch
+         #accept.prob = accept.prob + chain$accept
+ 
+         X_n = matrix(state[1:n.X], nrow = 3, ncol = N + 1)
+         theta = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta 
+         X_avg = X_avg + state[1:n.X]
+         param_mat[i, 1:n.theta] = theta
+ 
+         Sigma = numeric(length = 3)
+         f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(theta))
+         del_X = t(diff(t(X_n)))
+         beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+         Sigma[1] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[1])
+         Sigma[2] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[2])
+         Sigma[3] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[3])
+ 
+         param_mat[i, (n.theta + 1):(n.theta + n.sigma)] = Sigma
+         init = state
+     }
+     #print(accept.prob / n)
+     X_avg = X_avg / n
+     final_output = list(param_mat, X_avg, accept.prob / n)
+     return(final_output)
+ }
> 
> 
> # Numerical method to sample from SDE
> euler_maruyama <- function(X0, del_t, N, theta, Sigma) {
+     X = matrix(, nrow = 3, ncol = N + 1)
+     X[, 1] = X0
+     for (i in 2:(N + 1))
+         X[, i] = X[, i - 1] + t(drift_fun_true(X[, i - 1], theta)) * del_t + rmvnorm(1, sigma = del_t * Sigma)
+     return(X)
+ }
> # X = euler_maruyama(c(1,1,1), 0.1, 20, c(1,2,3), diag(2,3))
> 
> 
> # hyper-parameters
> to = 0 # initial time
> tf = 20 # final time
> Nobs = 20 # no of observations (Y) per time step
> del_t = 0.01 # discrete approximation of dt
> tau_o = matrix(rep(0, 3), nrow = 3, ncol = 1) # prior mean for X[0], i.e. initial state of Lorenz-63 oricess
> lam_o = diag(10, 3) # prior covariance matrix of X[0]
> inv.lam_o = solve(lam_o)
> alpha1 = 20 # Prior for \sigma is Gamma (alpha1, beta1)
> alpha2 = 56 # Prior for \rho is Gamma (alpha2, beta2)
> alpha3 = 6 # Prior for \beta is Gamma (alpha3, beta3)
> beta1 = 0.5
> beta2 = 0.5
> beta3 = 0.5
> a4 = 2
> b4 = .6
> tau1 = 5
> tau0 = 0.5
> 
> K = (tf - to) * Nobs # no of real life observations, i.e. size of Y
> N = (tf - to) / del_t # no of discretizations of the Lorenz-63, i.e. size of X
> seq.Y = seq(2, N + 1, N / K)
> N = tail(seq.Y, 1)
> burn_in = 5000 / del_t
> R = diag(1 / 20, 3) # observational error
> inv_R = diag(20,3)
> mu = 0
> sigma2 = 10
> mu_truth = c(-10, 28, 0, 10, -1, rep(0, 3), -8 / 3, rep(0, 11), 1, rep(0, 4), -1, rep(0, 7))
> non_zero = c(4, 5, 7, 8, 12, 24, 29) - 3
> param_i = c(1, 2, 4, 9)
> n.X = 3 * (N + 1)
> n.theta = 33
> n.sigma = 3
> n.param = n.X + n.theta + n.sigma
> q = rep(0.1, n.theta) #runif(n.theta)
> q[non_zero] = 0.9
> n <- 5e4
> 
> #X_total = euler_maruyama(c(0,0,25), del_t, N + burn_in, c(10, 28, 8 / 3), diag(.6, 3)) # generating sample from Lorenz-63
> #X = X_total[, (burn_in):(N + burn_in)]
> #save(X, file = 'burninX6_by_10')
> load('burninX6_by_10')
> X = X[, 1:(N + 1)]
> Y = X[, seq(2, N + 1, N / K)] + t(rmvnorm(K, mean = rep(0, 3), sigma = R)) # observations from Lorenz-63
> init = numeric(n.X + n.theta)
> 
> init[(1:n.X)] <- as.numeric(X) #runif(n.param, 0, 5)
> 
> init[(n.X + 1):(n.X + n.theta)] <- rmvnorm(1,mu_truth, sigma = diag(1 / 50, n.theta))
> 
> #load('l63_linch_T_20_2e3_cwise_1_spikes')
> #ans = to_save[[1]]
> #pm = ans[[1]][, 1:(n.sigma + n.theta)]
> #init[(n.X + 1):(n.X + n.theta)] = colMeans(pm[1e3:2e3,1:n.theta])
> 
> 
> #sigma_Y = mean(diag(var(t(Y))))
> #tau0 = sqrt(sigma_Y / (10 * K))/10
> #tau1 = sqrt(sigma_Y * max((n.theta ^ 2.1) / (100 * K), log(K)))*2
> 
> load('../l63_linch_T_20_5e5_1')
> var1 = cov(to_save[[1]][[1]][, 1:33])
> scale_vec = 2.7 * sqrt(diag(var1))
> ans = linchpin(n, init, scale_vec)
[1] 5000
       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
[1,] 0.2804 0.2010 0.2126 0.2428 0.2060 0.2432 0.1976 0.2158 0.2336 0.2748
[2,] 0.2288 0.1542 0.2562 0.2060 0.2178 0.2504 0.1638 0.2040 0.2554 0.2666
[3,] 0.3396 0.3302 0.2012 0.2396 0.2684 0.2624 0.2146 0.2444 0.2528 0.0828
      [,11]
[1,] 0.2848
[2,] 0.2706
[3,] 0.2392
[1] 10000
       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
[1,] 0.2686 0.1928 0.2092 0.2393 0.1995 0.2399 0.1918 0.2145 0.2315 0.2792
[2,] 0.2192 0.1407 0.2407 0.1923 0.2023 0.2386 0.1541 0.1877 0.2411 0.2526
[3,] 0.3374 0.3130 0.1993 0.2386 0.2675 0.2580 0.2159 0.2433 0.2523 0.0782
      [,11]
[1,] 0.2827
[2,] 0.2586
[3,] 0.2396
[1] 15000
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2654667 0.1926667 0.2098667 0.2354667 0.1997333 0.2378667 0.1923333
[2,] 0.2166000 0.1349333 0.2344667 0.1868667 0.1996667 0.2340000 0.1478000
[3,] 0.3364000 0.3138000 0.1997333 0.2296000 0.2663333 0.2589333 0.2149333
          [,8]      [,9]      [,10]     [,11]
[1,] 0.2130667 0.2308667 0.27873333 0.2808667
[2,] 0.1856667 0.2368667 0.24953333 0.2554667
[3,] 0.2420667 0.2509333 0.07866667 0.2423333
[1] 20000
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 0.26455 0.19010 0.20795 0.23590 0.19830 0.23480 0.19165 0.21305 0.22860
[2,] 0.21290 0.13420 0.23295 0.18485 0.19710 0.23075 0.14715 0.18500 0.23620
[3,] 0.33545 0.31215 0.19605 0.22795 0.26475 0.25705 0.21335 0.24260 0.25285
       [,10]  [,11]
[1,] 0.27785 0.2797
[2,] 0.24505 0.2551
[3,] 0.07750 0.2446
[1] 25000
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 0.26440 0.18952 0.20692 0.23644 0.19760 0.23456 0.18984 0.21072 0.22744
[2,] 0.21264 0.13112 0.23428 0.18440 0.19436 0.23108 0.14676 0.18492 0.23472
[3,] 0.33488 0.31276 0.19568 0.22828 0.26460 0.25708 0.21184 0.24348 0.25176
       [,10]   [,11]
[1,] 0.27744 0.27648
[2,] 0.24544 0.25536
[3,] 0.07836 0.24500
[1] 30000
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2631333 0.1904667 0.2072333 0.2370333 0.1957667 0.2330667 0.1889333
[2,] 0.2131000 0.1311000 0.2334000 0.1838000 0.1929333 0.2294333 0.1454333
[3,] 0.3331667 0.3129333 0.1947000 0.2297000 0.2624333 0.2569667 0.2114333
          [,8]   [,9]      [,10]     [,11]
[1,] 0.2105000 0.2266 0.27706667 0.2749667
[2,] 0.1850333 0.2350 0.24480000 0.2533333
[3,] 0.2436667 0.2519 0.07873333 0.2446333
[1] 35000
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2641429 0.1904000 0.2071143 0.2373429 0.1965143 0.2325714 0.1892571
[2,] 0.2134857 0.1303429 0.2343714 0.1816571 0.1929143 0.2285714 0.1450857
[3,] 0.3335714 0.3113143 0.1947143 0.2303714 0.2620571 0.2553143 0.2104857
          [,8]      [,9]      [,10]     [,11]
[1,] 0.2078857 0.2270857 0.27594286 0.2743429
[2,] 0.1843714 0.2346286 0.24362857 0.2526000
[3,] 0.2433714 0.2512286 0.07805714 0.2443429
[1] 40000
         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
[1,] 0.263975 0.190325 0.206625 0.237800 0.197225 0.233000 0.188875 0.207725
[2,] 0.213375 0.130400 0.234100 0.181525 0.192825 0.227750 0.144125 0.184675
[3,] 0.333600 0.313075 0.193775 0.230775 0.261450 0.253925 0.209425 0.243250
        [,9]    [,10]    [,11]
[1,] 0.22610 0.274975 0.274025
[2,] 0.23525 0.243750 0.253225
[3,] 0.24965 0.078300 0.245325
[1] 45000
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2634444 0.1898889 0.2062667 0.2371333 0.1965778 0.2336222 0.1872444
[2,] 0.2128667 0.1313333 0.2334000 0.1811111 0.1924667 0.2273556 0.1439333
[3,] 0.3341556 0.3119556 0.1936000 0.2307556 0.2633778 0.2534444 0.2094444
          [,8]      [,9]      [,10]     [,11]
[1,] 0.2077556 0.2258889 0.27586667 0.2737111
[2,] 0.1849778 0.2346000 0.24311111 0.2539556
[3,] 0.2432222 0.2485556 0.07857778 0.2451556
[1] 50000
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 0.26384 0.19076 0.20580 0.23594 0.19712 0.23374 0.18746 0.20786 0.22516
[2,] 0.21274 0.13148 0.23232 0.18130 0.19118 0.22596 0.14444 0.18440 0.23574
[3,] 0.33442 0.31138 0.19250 0.22988 0.26210 0.25310 0.20942 0.24306 0.24898
       [,10]   [,11]
[1,] 0.27608 0.27208
[2,] 0.24270 0.25416
[3,] 0.07872 0.24522
> #plot.ts(ans[[1]][, param_i])
> #plot.ts(ans[[1]][, non_zero])
> chain_info = capture.output(cat("no of samples from MC is ", n, " \n starting from previous run previous run", "\n priors spike slab ", " time period ",
+                             tf, " lam_0 is 10"))
> 
> print(chain_info)
[1] "no of samples from MC is  50000  "                
[2] " starting from previous run previous run "        
[3] " priors spike slab   time period  20  lam_0 is 10"
> to_save = list(ans, chain_info)
> save(to_save, file = "l63_linch_T_20_5e4_cwise_1_spikes_init_theta")
> pm = ans[[1]][, 1:(n.sigma + n.theta)]
> 
> print(matrix(colMeans(pm), nrow = 3))
            [,1]        [,2]       [,3]         [,4]          [,5]         [,6]
[1,] -9.83888826  9.82930718 -0.1149730 -0.028216543  0.0012932383  0.005142373
[2,] 28.12960049 -1.09785667 -0.0810342 -0.031018357 -0.0003897437  0.004733137
[3,]  0.03319952 -0.05393563 -2.6468899  0.004865742  0.0005565334 -0.001447362
           [,7]         [,8]          [,9]        [,10]         [,11]     [,12]
[1,] 0.01398724 0.0035230077 -0.0024030105  0.007074066 -0.0007773166 0.7817761
[2,] 0.01980378 0.0008417767 -1.0028423592 -0.067342502  0.0027607285 0.7292894
[3,] 0.99740999 0.0017325800 -0.0005579138  0.048739726 -0.0004889417 0.5993304
> 
> pm2 = ans[[1]][, (n.sigma + n.theta + 1):(n.sigma + 2 * n.theta)]
> print(matrix(colMeans(pm2), nrow = 3))
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 1.00000 1.00000 0.01626 0.01120 0.01020 0.01124 0.01126 0.01112 0.01106
[2,] 1.00000 0.87548 0.02202 0.01178 0.01090 0.01138 0.00982 0.01122 0.86860
[3,] 0.01356 0.01238 1.00000 0.01068 0.01106 0.01108 0.86344 0.01080 0.01138
       [,10]   [,11]
[1,] 0.01278 0.01106
[2,] 0.01514 0.01090
[3,] 0.01074 0.01134
> 
> proc.time()
     user    system   elapsed 
66229.124   197.812 69771.854 
