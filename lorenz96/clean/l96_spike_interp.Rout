
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin17.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> set.seed(1)
> library(mvtnorm)
> library(mcmc)
> library(invgamma)
> 
> make_tilde <- function(X, t) {
+     X_vec = c(1, X[1], X[2], X[3], X[4], X[1] ^ 2, X[2] ^ 2, X[3] ^ 2, X[4] ^ 2, X[1] * X[2], X[1] * X[3], X[1] * X[4],
+               X[2] * X[3], X[2] * X[4], X[3] * X[4], t, t ^ 2)
+     return(X_vec)
+ }
> # drifet function for Lorenz-63
> drift_fun <- function(X, t, B) {
+     #print(make_tilde(X,t))
+     tildeX = matrix(make_tilde(X, t), nrow = 17, ncol = 1)
+     B_mat = matrix(B, nrow = N.l96)
+     ans = B_mat %*% tildeX
+     return(ans)
+ }
> 
> drift_fun_true <- function(X, theta) {
+     ans = matrix(, nrow = N.l96, ncol = 1)
+     for (i in 0:(N.l96 - 1)) {
+         ans[i + 1, 1] = (X[(i + 1) %% N.l96 + 1] - X[(i - 2) %% N.l96 + 1]) * X[(i - 1) %% N.l96 + 1] - X[i + 1] + theta
+     }
+     return(ans)
+ }
> 
> ludfun <- function(state, gamma) {
+     # State is the vector storing the vectors of length 3*N + 12. The first 3*(N+1) terms are Xs. The next three terms are the parameters \sigma, \rho & 
+     # \beta. The remaining 6 terms are the \Sigma matrix. Definition of Sigma below shows how the symmetric matrix is constructed.
+ 
+     X_n = matrix(state[1:n.X], nrow = N.l96, ncol = N + 1)
+     B_vec = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     B_mat = matrix(B_vec, nrow = N.l96)
+ 
+     X_t = X_n[, seq(2, N + 1, N / K)]
+ 
+     #######################################################################
+     p1 = (sum(dmvnorm(t(Y - X_t), sigma = R, log = TRUE)))
+     #- 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o))
+     ######################################################################
+     B_cov_gamma = gamma * (tau1 ^ 2) + (1 - gamma) * (tau0 ^ 2)
+     p2 = dmvnorm(B_vec, sigma = diag(B_cov_gamma), log = TRUE)
+     #p2 = (alpha1 - 1) * log(theta[1]) - theta[1] / beta1 + (alpha2 - 1) * log(theta[2]) - theta[2] / beta2 + (alpha3 - 1) * log(theta[3]) - theta[3] / beta3
+ 
+ 
+     f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(B_vec))
+     #f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, B_vec, list(1,2))
+     del_X = t(diff(t(X_n)))
+     beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+     p3 = -(a4 + N / 2) * sum(log(b4 + beta_tmp))
+ 
+     return(p1 + p2 + p3)
+ 
+ }
> 
> ludfun.X <- function(state, gamma, all) {
+     # State is the vector storing the vectors of length 3*N + 12. The first 3*(N+1) terms are Xs. The next three terms are the parameters \sigma, \rho & 
+     # \beta. The remaining 6 terms are the \Sigma matrix. Definition of Sigma below shows how the symmetric matrix is constructed.
+     all[1:n.X] = state
+     X_n = matrix(all[1:n.X], nrow = N.l96, ncol = N + 1)
+     B_vec = all[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta    
+     B_mat = matrix(B_vec, nrow = N.l96)
+ 
+     # Extracting observed data
+     X_t = X_n[, seq(2, N + 1, N / K)]
+ 
+     #######################################################################
+     p1 = (sum(dmvnorm(t(Y - X_t), sigma = R, log = TRUE)))
+     #- 0.5 * t(t(t(X_n[, 1])) - tau_o) %*% inv.lam_o %*% (t(t(X_n[, 1])) - tau_o))
+     ######################################################################
+     B_cov_gamma = gamma * (tau1 ^ 2) + (1 - gamma) * (tau0 ^ 2)
+     p2 = dmvnorm(B_vec, sigma = diag(B_cov_gamma), log = TRUE)
+     #p2 = (-1 / 2) * sum((B_vec - mu) ^ 2) / sigma2
+ 
+     #f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(B_vec))
+     f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(B_vec))
+     #f = sapply(split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), drift_fun, B_vec, list(1,2))
+     del_X = t(diff(t(X_n)))
+     beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+     p3 = -(a4 + N / 2) * sum(log(b4 + beta_tmp))
+ 
+     return(p1 + p2 + p3)
+ 
+ }
> 
> sample_gamma <- function(B_vec) {
+     gamma = numeric(length = n.theta)
+     for (i in 1:n.theta) {
+         prob = q[i] * dnorm(B_vec[i], sd = tau1) / (q[i] * dnorm(B_vec[i], sd = tau1) + (1 - q[i]) * dnorm(B_vec[i], sd = tau0))
+         gamma[i] = rbinom(1, 1, prob)
+     }
+     return(gamma)
+ }
> 
> MH.X <- function(init, n, scale, gamma, B_vec) {
+     chain = matrix(, nrow = n, ncol = n.X)
+     accept.prob = 0
+     for (i in 1:n) {
+         prop = sapply(init, function(t) rnorm(1, t, scale))
+         prop_ludf = c(prop, B_vec)
+         init_ludf = c(init, B_vec)
+         if (log(runif(1)) < (ludfun(prop_ludf, gamma) - ludfun(init_ludf, gamma))) {
+             init = prop
+             accept.prob = accept.prob + 1
+         }
+         chain[i,] = init
+     }
+     ans = list(chain, accept.prob / n)
+     return(ans)
+ }
> 
> MH.B <- function(index, init, n, scale, gamma, state) {
+     chain = numeric(length = n)
+     accept.prob = 0
+     prop_ludf = state
+     init_ludf = state
+     for (i in 1:n) {
+         prop = rnorm(1, init, scale)
+         prop_ludf[n.X + index] = prop
+         init_ludf[n.X + index] = init
+         if (log(runif(1)) < (ludfun(prop_ludf, gamma) - ludfun(init_ludf, gamma))) {
+             init = prop
+             accept.prob = accept.prob + 1
+         }
+         chain[i] = init
+     }
+     ans = list(chain, accept.prob / n)
+     return(ans)
+ }
> 
> linchpin <- function(n, init) {
+     X_avg = numeric(length = n.X)
+     param_mat = matrix(, nrow = n, ncol = 2 * n.theta + n.sigma)
+     
+     scale.B = scale
+ 
+     accept.prob = numeric(1 + n.theta)
+     state = init
+ 
+     for (i in 1:n) {
+         gamma = sample_gamma(init[(n.X + 1):(n.X + n.theta)])
+         param_mat[i, (n.theta + n.sigma + 1):(2 * n.theta + n.sigma)] = gamma
+ 
+         if (i %% (n / 5) == 0) {
+             print(i)
+             print(accept.prob[1]/i)
+             print(matrix(accept.prob[2:(n.theta + 1)] / i, nrow = N.l96))
+         }
+ 
+         all = init
+         chain = metrop(ludfun.X, initial = init[1:n.X], nbatch = 1, scale = scale.X, gamma = gamma, all = all)
+         accept.prob[1] = accept.prob[1] + chain$accept
+         state[1:n.X] = chain$batch
+ 
+ 
+         for (j in 1:n.theta) {
+ 
+             ans = MH.B(j, init[n.X + j], 1, scale.B[j], gamma, state)
+             accept.prob[j + 1] = accept.prob[j + 1] + ans[[2]]
+             state[n.X + j] = ans[[1]]
+         }
+ 
+         X_n = matrix(state[1:n.X], nrow = N.l96, ncol = N + 1)
+         theta = state[(n.X + 1):(n.X + n.theta)] # vector of \sigma, \rho and \beta 
+         X_avg = X_avg + state[1:n.X]
+         param_mat[i, 1:n.theta] = theta
+ 
+         Sigma = numeric(length = n.sigma)
+         f = mapply(drift_fun, X = split(X_n, rep(1:ncol(X_n), each = nrow(X_n))), t = del_t * (0:N), MoreArgs = list(theta))
+         del_X = t(diff(t(X_n)))
+         beta_tmp = rowSums((del_X / del_t - f[, - (N + 1)]) ^ 2) * del_t / 2
+         for (j in 1:n.sigma) {
+             Sigma[j] = rinvgamma(1, shape = N / 2 + a4, rate = b4 + beta_tmp[j])
+         }
+ 
+         param_mat[i, (n.theta + 1):(n.theta + n.sigma)] = Sigma
+         init = state
+     }
+     #print(accept.prob / n)
+     save.X = state[1:n.X]
+     X_avg = X_avg / n
+     final_output = list(param_mat, X_avg, save.X,accept.prob / n)
+     return(final_output)
+ }
> 
> 
> # Numerical method to sample from SDE
> euler_maruyama <- function(X0, del_t, N, theta, Sigma) {
+     X = matrix(, nrow = N.l96, ncol = N + 1)
+     X[, 1] = X0
+     for (i in 2:(N + 1))
+         X[, i] = X[, i - 1] + t(drift_fun_true(X[, i - 1], theta)) * del_t + rmvnorm(1, sigma = del_t * Sigma)
+     return(X)
+ }
> # X = euler_maruyama(c(1,1,1), 0.1, 20, c(1,2,3), diag(2,3))
> 
> 
> # hyper-parameters
> to = 0 # initial time
> tf = 10 # final time
> Nobs = 20 # no of observations (Y) per time step
> N.l96 = 4
> del_t = 0.01 # discrete approximation of dt
> a4 = 2
> b4 = .5
> tau1 = 10
> tau0 = 0.5
> 
> K = (tf - to) * Nobs # no of real life observations, i.e. size of Y
> N = (tf - to) / del_t # no of discretizations of the Lorenz-63, i.e. size of X
> burn_in = 5000 #/ del_t
> R = diag(.05, N.l96) # observational error
> inv_R = diag(1 / (0.05), N.l96)
> mu = 0
> sigma2 = 10
> mu_truth = c(rep(8, 4), as.numeric(diag(rep(-1, 4))), rep(0, 16), 0, 0, -1, 0, 0, 1, 0, 1, 0, -1, rep(0, 5), -1, 1, 0, 1, 0, -1, rep(0, 11)) #c(-10, 28, 0, 10, -1, rep(0, 3), -8 / 3, rep(0, 11), 1, rep(0, 4), -1, rep(0, 7))
> non_zero = c(1, 2, 3, 4, 5, 10, 15, 20, 39, 42, 44, 46, 52, 53, 55, 57)
> param_i = 1:4
> n.theta = 68
> n.sigma = N.l96
> q = rep(0.1, n.theta) #runif(n.theta)
> q[non_zero] = 0.9
> seq.Y = seq(2, N + 1, N / K)
> N = tail(seq.Y, 1)
> n.X = N.l96 * (N + 1)
> n.param = n.X + n.theta + n.sigma
> 
> n <- 1e5
> 
> 
> 
> X_total = euler_maruyama(rep(0, N.l96), del_t, N + burn_in, 8, diag(.5, N.l96)) # generating sample from Lorenz-63
> X = X_total[, (burn_in):(N + burn_in)]
> X = X[, 1:(N + 1)]
> Y = X[, seq(2, N + 1, N / K)] + rnorm(K, sd = sqrt(R)) # observations from Lorenz-63
> init = numeric(n.X + n.theta)
> 
> init[(n.X + 1):(n.X + n.theta)] <- rmvnorm(1, mu_truth + rnorm(n.theta, sd = 1.5), sigma = diag(1 / 50, n.theta)) #rmvnorm(1, c(10, 28, 8 / 3), sigma = diag(0.5, 3)) # random initial values for MCMC
> 
> 
> X.interp = X #matrix(-50,nrow = 3, ncol = N + 1)
> y.index = 1
> #X.interp[,1] = X[,1]
> for (i in seq(2, N + 1, N / K)) {
+     if (i == 2) {
+         X.interp[, 2] = Y[, 1]
+     } else {
+         for (j in 1:N.l96) {
+             X.interp[j, (i - N / K + 1):i] = seq(Y[j, y.index], Y[j, y.index + 1], (Y[j, y.index + 1] - Y[j, y.index]) * K / N)[-1]
+         }
+         y.index = y.index + 1
+     }
+ 
+ }
> 
> init[(1:n.X)] <- as.numeric(X.interp)
> 
> 
> sigma_Y = mean(diag(var(t(Y))))
> tau0 = sqrt(sigma_Y / (10 * K)) * 2
> tau1 = sqrt(sigma_Y * max((n.theta ^ 2.1) / (100 * K), log(K))) / 4
> 
> tau0 = sqrt(sigma_Y / (10 * K)) * 1.5
> tau1 = sqrt(sigma_Y * max((n.theta ^ 2.1) / (100 * K), log(K))) / 2
> 
> load('l96_linch_spike_5e2')
> var1 = cov(to_save[[1]][[1]][, 1:n.theta])
> scale_vec = 1.2 * sqrt(diag(var1))
> 
> scale = rep(n.theta)
> 
> scale = scale_vec # tf = 5 Sigma = 0.1  change of above
> scale[c(1)] = .4 * scale_vec[c(1)] ## Sigma = .5
> scale[c(2)] = 3.2 * scale_vec[c(2)]
> scale[c(3)] = 12 * scale_vec[c(3)]
> scale[c(4)] = 5.7 * scale_vec[c(4)]
> scale[c(5)] = 0.7 * scale_vec[c(5)]
> scale[c(6)] = 3.5 * scale_vec[c(6)]
> scale[c(14, 16)] = 3 * scale_vec[c(14, 16)]
> scale[c(9, 13, 18, 62)] = 2.5 * scale_vec[c(9, 13, 18, 62)]
> scale[c(10)] = 0.4 * scale_vec[c(10)]
> scale[c(8, 12, 29, 32, 55)] = 0.5 * scale_vec[c(8, 12, 29, 32, 55)]
> scale[c(67)] = 0.3 * scale_vec[c(67)]
> scale[c(21, 24, 25, 26, 27, 28, 30, 31, 35, 65)] = 0.6 * scale_vec[c(21, 24, 25, 26, 27, 28, 30, 31, 35, 65)]
> scale[c(17, 19)] = 2.5 * scale_vec[c(17, 19)]
> scale[c(7, 20, 61, 64)] = 2 * scale_vec[c(7, 20, 61, 64)]
> scale[c(23)] = 1.8 * scale_vec[c(23)]
> scale[c(49, 52)] = 0.7 * scale_vec[c(49, 52)]
> scale[c(40, 42, 43)] = 1.2 * scale_vec[c(40, 42, 43)]
> scale[c(22, 37, 38, 41, 45, 46, 47, 48, 49, 50, 54, 56, 58, 59, 60, 61)] = 1.5 * scale_vec[c(22, 37, 38, 41, 45, 46, 47, 48, 49, 50, 54, 56, 58, 59, 60, 61)]
> scale[c(11, 15, 39, 53, 66, 68)] = 0.8 * scale_vec[c(11, 15, 39, 53, 66, 68)]
> 
> scale.X = 0.0018
> 
> # These values are generate ffrom the same code with difference scale and scale.X, which can be found in attr loaded with this file
> load('l96_5e5_cwise_spikes_interp_diffuse_init_theta_try')
> init[(n.X + 1):(n.X + n.theta)] = colMeans(to_save[[1]][[1]][3e4:5e4, 1:(n.theta)])
> #init[1:n.X] = to_save[[1]][[2]]
> 
> ans = linchpin(n, init)
[1] 20000
[1] 0.255
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 0.28600 0.23630 0.28495 0.31805 0.31605 0.28025 0.26650 0.26220 0.26720
[2,] 0.26765 0.28725 0.22995 0.23900 0.24130 0.21635 0.23790 0.30350 0.24200
[3,] 0.30645 0.31830 0.28640 0.30245 0.32345 0.28575 0.31370 0.26295 0.35915
[4,] 0.25900 0.25530 0.28765 0.28915 0.28620 0.28075 0.29045 0.26880 0.27765
       [,10]   [,11]   [,12]   [,13]   [,14]   [,15]   [,16]   [,17]
[1,] 0.24815 0.29035 0.28980 0.21785 0.31100 0.27540 0.38670 0.31780
[2,] 0.21520 0.29290 0.24180 0.23830 0.24295 0.25290 0.24955 0.28600
[3,] 0.30385 0.34660 0.30760 0.32955 0.42540 0.25645 0.23060 0.32380
[4,] 0.33575 0.30355 0.25475 0.27920 0.26455 0.26365 0.30800 0.27795
[1] 40000
[1] 0.2535
         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
[1,] 0.279000 0.225625 0.280100 0.314300 0.302600 0.272200 0.259725 0.254800
[2,] 0.265775 0.283875 0.232375 0.239475 0.240475 0.217850 0.238000 0.307675
[3,] 0.308875 0.319200 0.284000 0.302325 0.329775 0.286175 0.318625 0.267000
[4,] 0.269725 0.263950 0.292250 0.298350 0.292275 0.292500 0.302950 0.276175
         [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]
[1,] 0.260600 0.238625 0.285875 0.283700 0.205625 0.300350 0.266275 0.379500
[2,] 0.239625 0.212550 0.293725 0.240175 0.237025 0.242325 0.251175 0.249175
[3,] 0.358000 0.306250 0.346800 0.312175 0.332675 0.425500 0.259425 0.235150
[4,] 0.287700 0.349375 0.312025 0.263175 0.290975 0.277250 0.274300 0.315550
       [,17]
[1,] 0.30875
[2,] 0.28395
[3,] 0.32330
[4,] 0.28790
[1] 60000
[1] 0.2504667
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2788167 0.2229167 0.2795167 0.3111500 0.3034333 0.2728500 0.2577833
[2,] 0.2607333 0.2814000 0.2284833 0.2359333 0.2373833 0.2149500 0.2332000
[3,] 0.3088333 0.3186000 0.2851167 0.3038167 0.3287833 0.2879167 0.3208000
[4,] 0.2766167 0.2697333 0.2983167 0.3039333 0.2957833 0.2981000 0.3115167
          [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]
[1,] 0.2534000 0.2624333 0.2378000 0.2840500 0.2838000 0.2036000 0.2986333
[2,] 0.3018333 0.2358167 0.2088500 0.2906333 0.2357333 0.2326000 0.2386000
[3,] 0.2690667 0.3594500 0.3065667 0.3447000 0.3140667 0.3320167 0.4246500
[4,] 0.2812000 0.2933333 0.3550333 0.3185167 0.2703333 0.2962000 0.2824167
         [,15]     [,16]     [,17]
[1,] 0.2659000 0.3756667 0.3082833
[2,] 0.2479833 0.2433667 0.2789500
[3,] 0.2588833 0.2356833 0.3237500
[4,] 0.2801667 0.3209167 0.2931167
[1] 80000
[1] 0.2504875
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
[1,] 0.2818000 0.2267500 0.2823625 0.3144250 0.3071875 0.2768250 0.2610125
[2,] 0.2575000 0.2787750 0.2265500 0.2350375 0.2357500 0.2138500 0.2303125
[3,] 0.3061875 0.3174250 0.2827750 0.3012875 0.3267125 0.2855125 0.3196250
[4,] 0.2776750 0.2714125 0.3013875 0.3054375 0.2965500 0.2994625 0.3114125
          [,8]      [,9]     [,10]    [,11]     [,12]     [,13]     [,14]
[1,] 0.2573125 0.2656750 0.2424875 0.288125 0.2885375 0.2071250 0.3040500
[2,] 0.2988500 0.2341125 0.2063250 0.287025 0.2336375 0.2293500 0.2367750
[3,] 0.2668750 0.3566500 0.3042625 0.343250 0.3133375 0.3326625 0.4216375
[4,] 0.2811500 0.2945000 0.3568500 0.321725 0.2710000 0.2976125 0.2827500
         [,15]     [,16]     [,17]
[1,] 0.2705125 0.3799375 0.3141625
[2,] 0.2431875 0.2404750 0.2762875
[3,] 0.2576750 0.2324125 0.3217625
[4,] 0.2818625 0.3234625 0.2947500
[1] 100000
[1] 0.25393
        [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,] 0.28365 0.22730 0.28328 0.31586 0.30916 0.27794 0.26247 0.25743 0.26789
[2,] 0.25880 0.27983 0.22765 0.23750 0.23781 0.21696 0.23230 0.30223 0.23665
[3,] 0.30636 0.31621 0.28341 0.30035 0.32706 0.28565 0.32095 0.26778 0.35675
[4,] 0.28021 0.27154 0.30324 0.30757 0.29750 0.30131 0.31240 0.28242 0.29482
       [,10]   [,11]   [,12]   [,13]   [,14]   [,15]   [,16]   [,17]
[1,] 0.24341 0.28951 0.28995 0.20851 0.30607 0.27180 0.38167 0.31604
[2,] 0.20858 0.28998 0.23505 0.23160 0.23877 0.24588 0.24345 0.27834
[3,] 0.30543 0.34295 0.31469 0.33446 0.42335 0.25818 0.23281 0.32254
[4,] 0.35610 0.32345 0.27223 0.29835 0.28400 0.28384 0.32443 0.29619
> 
> chain_info = capture.output(cat("no of samples from MC is ", n, " \n starting from previous run ", "\n priors spike slab ", " time period ",
+                                 tf, " Sigma is .5"))
> 
> print(chain_info)
[1] "no of samples from MC is  1e+05  "                
[2] " starting from previous run  "                    
[3] " priors spike slab   time period  10  Sigma is .5"
> 
> attr = list('to' = to, 'tf' = tf, 'Nobs' = Nobs, 'N.l96' = N.l96, 'del_t' = del_t, 'a4' = a4, 'b4' = b4, 'tau0' = tau0, 'tau1' = tau1,
+             'K' = K, 'N' = N, 'burn_in' = burn_in, 'R' = R, 'inv_R' = inv_R, 'mu_truth' = mu_truth, 'non_zero' = non_zero, 'param_i' = param_i,
+             'n.X' = n.X, 'n.theta' = n.theta, 'n.sigma' = n.sigma, 'n.param' = n.param, 'q' = q, 'seq.Y' = seq.Y, 'n' = n, 'scale_vec' = scale_vec,
+             'scale' = scale, 'scale.X' = scale.X)
> 
> to_save = list(ans, chain_info)
> save(to_save,attr, file = "l96_1e5_cwise_spikes_interp_diffuse_init_theta_try")
> pm = ans[[1]][, 1:(n.sigma + n.theta)]
> 
> print(matrix(colMeans(pm), nrow = N.l96))
         [,1]        [,2]          [,3]        [,4]        [,5]          [,6]
[1,] 8.953809 -0.59248803  0.0004957156  0.01891671 -0.05900923 -0.0384560393
[2,] 6.665104  0.01236148 -0.8769922162 -0.01152494 -0.07522997  0.0032386171
[3,] 7.348784  0.01722083  0.0369985486 -0.58413179  0.03996803  0.0005500228
[4,] 6.170384  0.04616565  0.0062640808 -0.03584485 -1.31394312  0.0230962158
              [,7]         [,8]         [,9]        [,10]       [,11]
[1,] -0.0089478839  0.001248178 0.0033958089 -0.020599581 -0.04490498
[2,] -0.0009766519  0.014459005 0.0116704224 -0.007863288  1.00247672
[3,] -0.0128921605 -0.051366159 0.0001827922 -0.980537060 -0.08397946
[4,]  0.0311562444  0.035018725 0.0744395473 -0.043434328  0.99470365
            [,12]       [,13]       [,14]         [,15]        [,16]
[1,] -0.009746137 -0.02019235  0.98038304 -0.9867469197 -0.077772640
[2,] -0.972953725  0.03457504 -0.03037224  0.0009782579 -0.006895666
[3,]  0.041524199  0.05014998  0.94674890 -0.0204388489 -0.044267867
[4,] -0.033921107 -1.02382671  0.04774527 -0.0372886124  0.016516432
            [,17]     [,18]
[1,] -0.007814480 0.4277335
[2,]  0.007972231 0.4228620
[3,]  0.013473584 0.5965093
[4,] -0.010359666 0.6271367
> 
> pm2 = ans[[1]][, (n.sigma + n.theta + 1):(n.sigma + 2 * n.theta)]
> print(matrix(colMeans(pm2), nrow = N.l96))
     [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
[1,]    1 0.88000 0.00690 0.01001 0.00831 0.00359 0.00291 0.00307 0.00335
[2,]    1 0.01172 0.97858 0.00891 0.01112 0.00304 0.00325 0.00333 0.00330
[3,]    1 0.00826 0.01614 0.80323 0.00858 0.00310 0.00333 0.00371 0.00326
[4,]    1 0.01515 0.00843 0.01781 0.99998 0.00314 0.00341 0.00396 0.00382
       [,10]   [,11]   [,12]   [,13]   [,14]   [,15]   [,16]   [,17]
[1,] 0.00331 0.00352 0.00353 0.00324 1.00000 1.00000 0.02973 0.00329
[2,] 0.00328 1.00000 1.00000 0.00363 0.00320 0.00322 0.00784 0.00313
[3,] 1.00000 0.00424 0.00348 0.00361 1.00000 0.00342 0.00914 0.00309
[4,] 0.00386 1.00000 0.00352 1.00000 0.00391 0.00372 0.01398 0.00339
> 
> proc.time()
      user     system    elapsed 
111294.773   1149.012 113475.590 
